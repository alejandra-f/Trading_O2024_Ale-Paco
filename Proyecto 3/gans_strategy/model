import tensorflow as tf
from tensorflow.keras import layers, models

def build_generator(latent_dim, num_features):
    model = models.Sequential()
    model.add(layers.Dense(256, activation='relu', input_dim=latent_dim))
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dense(1024, activation='relu'))
    model.add(layers.Dense(num_features, activation='tanh'))
    return model

def build_discriminator(input_shape):
    model = models.Sequential()
    model.add(layers.Dense(1024, activation='relu', input_shape=input_shape))
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model

def build_gan(generator, discriminator):
    model = models.Sequential()
    model.add(generator)
    discriminator.trainable = False
    model.add(discriminator)
    return model

def train_gan(data, latent_dim=100, epochs=10000, batch_size=64):
    num_features = data.shape[1]
    input_shape = (num_features,)
    generator = build_generator(latent_dim, num_features)
    discriminator = build_discriminator(input_shape)

    gan = build_gan(generator, discriminator)
    discriminator.compile(optimizer='adam', loss='binary_crossentropy')
    gan.compile(optimizer='adam', loss='binary_crossentropy')

    half_batch = batch_size // 2

    for epoch in range(epochs):
        # Entrenar Discriminador
        idx = np.random.randint(0, data.shape[0], half_batch)
        real_data = data[idx]

        noise = np.random.normal(0, 1, (half_batch, latent_dim))
        fake_data = generator.predict(noise)

        d_loss_real = discriminator.train_on_batch(real_data, np.ones((half_batch, 1)))
        d_loss_fake = discriminator.train_on_batch(fake_data, np.zeros((half_batch, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Entrenar Generador
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        valid_y = np.array([1] * batch_size)
        g_loss = gan.train_on_batch(noise, valid_y)

        if epoch % 100 == 0:
            print(f"{epoch} [D loss: {d_loss}] [G loss: {g_loss}]")

    return generator

def generate_scenarios(generator, n_scenarios, latent_dim=100):
    noise = np.random.normal(0, 1, (n_scenarios, latent_dim))
    scenarios = generator.predict(noise)
    scenarios_df = pd.DataFrame(scenarios)
    return scenarios_df
